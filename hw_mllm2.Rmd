---
title: "MA684_homework_08"
author: "Tingrui Huang"
date: "November 17, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="pdf",fig.align  = 'center')
library(ggplot2)
library(knitr)
library(gridExtra)
library(arm)
library(data.table)
library(foreign)
library(car)
library(stringr)
library(rstan)
library(zoo)

```


## Getting to know stan
Read through the tutorial on Stan
https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started

* Explore Stan website and Stan reference manual and try to connect them with 
Gelman and Hill 16 - 17.


# Data analysis 

## Using stan:

The folder olympics has seven judges' ratings of seven figure skaters (on two criteria: "technical merit" and "artistic impression") from the 1932 Winter Olympics. Take a look at 
http://www.stat.columbia.edu/~gelman/arm/examples/olympics/olympics1932.txt

```{r,echo=FALSE, fig.width=7,fig.height=3 ,out.width="0.8\\linewidth",message=FALSE}
olympics1932_na<-read.fwf("http://www.stat.columbia.edu/~gelman/arm/examples/olympics/olympics1932.txt",widths=c(2,14,9,9,9,9,9,9,9),skip=21,header = FALSE)
colnames(olympics1932_na)<- c("pair", "criterion", "judge_1",  "judge_2",  "judge_3",  "judge_4",  "judge_5" , "judge_6",  "judge_7")
olympics1932<-na.locf(olympics1932_na)
olympics1932$criterion<-str_trim(olympics1932$criterion)
olympics1932$pair<-str_trim(olympics1932$pair)
ggplot(melt(olympics1932,id.vars=c("pair","criterion")))+geom_point()+aes(x=pair,y=value,group=variable,color=variable)+geom_line()+facet_grid(.~criterion)
molympics<-data.table(melt(olympics1932,id.vars=c("pair","criterion")))
molympics$value <- as.double(molympics$value)
olong <- merge(molympics[seq(1,98,by=2),],molympics[seq(2,98,by=2),],by=c("pair", "variable" ))
setnames(olong,c( "variable",  "value.x", "value.y"),c("Judge","Program","Performance"))
olympics_long <- olong[,list(Program,Performance,pair,Judge)]
head(olympics_long)
pair_country<-str_trim(read.csv("http://www.stat.columbia.edu/~gelman/arm/examples/olympics/olympics1932.txt",skip=3,nrows = 7,header=FALSE,stringsAsFactors=FALSE)$V3)
judge_country<-str_trim(read.csv("http://www.stat.columbia.edu/~gelman/arm/examples/olympics/olympics1932.txt",skip=12,nrows = 7,header=FALSE,stringsAsFactors=FALSE)$V2)
names(pair_country)<-1:7
names(judge_country)<-paste("judge",1:7,sep="_")
olympics_long$same_country<-1*(pair_country[olympics_long$pair]==judge_country[olympics_long$Judge])
```

use stan to fit a non-nested multilevel model (varying across skaters and judges) for the technical merit ratings.

\begin{eqnarray}
y_i &\sim& N(\mu+\gamma_{j[i]}+\delta_{k[i]},\sigma^2_y),\mbox{ for } i=1,\dots, n\\
\gamma_{j} &\sim& N(0,\sigma^2_{\gamma}) j=1,\dots, 7\\
\delta_{k} &\sim& N(0,\sigma^2_{\delta}) k=1,\dots, 7
\end{eqnarray}

https://github.com/stan-dev/example-models/blob/master/ARM/Ch.17/17.3_flight_simulator.stan
https://github.com/stan-dev/example-models/blob/master/ARM/Ch.17/17.3_non-nested_models.R
```{r}
fit_program<-lmer(Program~1+(1|pair) +  (1|Judge),olympics_long)
```

```{r}
dataList.1 <- list(N=49, n_judges=7, n_pairs=7,  judge=as.integer(olympics_long$Judge), pair=as.integer(olympics_long$pair), y=olympics_long$Program)
                   
skating_stan<-"
data {
  int<lower=0> N;
  int<lower=0> n_judges;
  int<lower=0> n_pairs;
  int<lower=0,upper=n_judges> judge[N];
  int<lower=0,upper=n_pairs> pair[N];
  vector[N] y;
}
parameters {
  real<lower=0> sigma;
  real<lower=0> sigma_gamma;
  real<lower=0> sigma_delta;
  vector[n_judges] gamma;
  vector[n_pairs] delta;
  real mu;
}
model {
  vector[N] y_hat;

  sigma ~ uniform(0, 100);
  sigma_gamma ~ uniform(0, 100);
  sigma_delta ~ uniform(0, 100);

  mu ~ normal(0, 100);
  
  gamma ~ normal(0, sigma_gamma);
  delta ~ normal(0, sigma_delta);

  for (i in 1:N)
    y_hat[i] = mu + gamma[judge[i]] + delta[pair[i]];
  y ~ normal(y_hat, sigma);
}
"
```

pilots <- read.table ("http://www.stat.columbia.edu/~gelman/arm/examples/pilots/pilots.dat", header=TRUE)

flight_simulator.sf1 <- stan(   model_code=skating_stan
, data=dataList.1, iter=2000, chains=4)


##  Multilevel logistic regression 

The folder `speed.dating` contains data from an experiment on a few hundred students that randomly assigned each participant to 10 short dates with participants of the opposite sex (Fisman et al., 2006). For each date, each person recorded several subjective numerical ratings of the other person (attractiveness, compatibility, and some other characteristics) and also wrote down whether he or she would like to meet the other person again. Label $y_{ij} = 1$ if person $i$ is interested in seeing person $j$ again $0$ otherwise.
And $r_{ij1},\dots, r_{ij6}$ as person $i$'s numerical ratings of person $j$ on the dimensions of attractiveness, compatibility, and so forth.
Please look at 
http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/Speed%20Dating%20Data%20Key.doc
for details.

```{r}
dating<-fread("http://www.stat.columbia.edu/~gelman/arm/examples/speed.dating/Speed%20Dating%20Data.csv")
```

1. Fit a classical logistic regression predicting $Pr(y_{ij} = 1)$ given person $i$'s 6 ratings of person $j$. Discuss the importance of attractiveness, compatibility, and so forth in this predictive model.

```{r}
dating_reg1 <- glm(match~attr_o +sinc_o +intel_o +fun_o +amb_o +shar_o,data=dating,family=binomial)
summary(dating_reg1)
```
\color{blue}
Fitted model: $logit(P(match=1))=-5.6+0.22X_{attractiveness}-0.019X_{sincere}+0.071X_{intellligent}+0.253X_{fun}-0.12X_{ambitious}+0.212X_{sharedinterests}$

The attractiveness, fun, ambitious and shared interests are statistically significant.

Attractiveness: this predictor has positive effects on the match of two person, for every unit increase in attractiveness, the log odds of match will increase by 0.22. In other words, the probability of match will be increased.

Fun: this predictor has positive effects on the match of two person, for every unit increase in attractiveness, the log odds of match will increase by 0.25. In other words, the probability of match will be increased.

Ambitious: this predictor has negative effects on the match of two person, for every unit increase in attractiveness, the log odds of match will decrease by 0.12. In other words, the probability of match will be decreased.

Shared Interests: this predictor has positive effects on the match of two person, for every unit increase in attractiveness, the log odds of match will increase by 0.21. In other words, the probability of match will be increased.

Overall, since all four variables are statistically significant, we can explain their effects based on their coefficients. Therefore, I would say "fun" has relatively greater effetcs on the probability of match, following by attractiveness, shared interests and ambitious.
\color{black}

2. Expand this model to allow varying intercepts for the persons making the evaluation; that is, some people are more likely than others to want to meet someone again. Discuss the fitted model.
```{r }
dating_reg2 <- glmer(match~gender+attr_o+sinc_o+intel_o+fun_o+amb_o+shar_o+(1|iid), data=dating, family=binomial)
summary(dating_reg2)
ranef(dating_reg2)$'iid'[1:5,]
```
\color{blue}
Fitted model: $P(match=1)=logit^{-1}(\alpha_0+\alpha_{j[i]}+0.153X_{gender}+0.235X_{attr}-0.013X_{sinc}+0.07X_{intel}+0.262X_{fun}-0.131X_{amb}+0.223X_{shar})$

$\alpha_{j} \sim N(\mu_{\sigma},\sigma^{2}_{iid})$

Each observtion(person) shares same fixed effects, but the intercept will be varied for different person. For example, the fitted model for the first person is:
$P(match=1)=logit^{-1}(-6.02+0.491+0.153X_{gender}+0.235X_{attr}-0.013X_{sinc}+0.07X_{intel}+0.262X_{fun}-0.131X_{amb}+0.223X_{shar})$

The interpretation will be similar to classic logistic regression. 
\color{black}

3. Expand further to allow varying intercepts for the persons being rated. Discuss the fitted model.
```{r }
dating_reg3 <- glmer(match~gender+attr_o+sinc_o+intel_o+fun_o+amb_o+shar_o+(1|iid)+(1|pid), data=dating, family=binomial)
summary(dating_reg3)
ranef(dating_reg3)$'iid'[1:5,]
```
\color{blue}
Comparing to the previous model, the difference is that the intercept for each observation(person) will be varied further by the random effects of the person being rated.

Fitted model: $P(match=1)=logit^{-1}(-8.25+\alpha^{iid}_{j[i]}+\alpha^{pid}_{j[i]}+0.171X_{gender}+0.336X_{attr}+0.02X_{sinc}+0.105X_{intel}+0.3X_{fun}-0.093X_{amb}+0.26X_{shar})$

$\alpha^{iid}_{j} \sim N(\mu_{\sigma},\sigma^{2}_{iid})$

$\alpha^{pid}_{j} \sim N(\mu_{\sigma},\sigma^{2}_{pid})$

\color{black}

4. You will now fit some models that allow the coefficients for attractiveness, compatibility, and the other attributes to vary by person. Fit a no-pooling model: for each person i, fit a logistic regression to the data $y_{ij}$ for the 10 persons j whom he or she rated, using as predictors the 6 ratings $r_{ij1},\dots,r_{ij6}$ . (Hint: with 10 data points and 6 predictors, this model is difficult to fit. You will need to simplify it in some way to get reasonable fits.)
```{r }
# No pooling model
dating_reg4 <- glm(match~attr_o +sinc_o +intel_o +fun_o +amb_o +shar_o+factor(iid)-1,data=dating,family = binomial)
summary(dating_reg4)
```

5. Fit a multilevel model, allowing the intercept and the coefficients for the 6 ratings to vary by the rater i.
```{r }
# Vary both intercept and slope
dating_reg5 <- glmer(match~attr_o +sinc_o +intel_o +fun_o +amb_o +shar_o+(1+attr_o|iid)+ (1+sinc_o|iid)+ (1+intel_o|iid)+ (1+fun_o|iid)+(1+amb_o|iid),data=dating,family=binomial)
summary(dating_reg5)
```

6. Compare the inferences from the multilevel model in (5) to the no-pooling model in (4) and the complete-pooling model from part (1) of the previous exercise.
```{r }
anova(dating_reg5,dating_reg4,dating_reg1)
```
\color{blue}
The last model which is the vary intercept and slope model has the lowest AIC. However, the no-pooling model has significantly lower deviance.
\color{black}