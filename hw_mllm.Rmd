---
title: "homework 07"
author: "Tingrui Huang"
date: "November 10, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,out.width="0.9\\linewidth",dev="png",fig.align  = 'center')
pacman::p_load(
ggplot2,
knitr,
arm,
data.table,
foreign,
gridExtra,
car,
stringr,
rstan,
rstanarm,
zoo
)
```



# Data analysis 


## CD4 percentages for HIV infected kids

The folder `cd4` has CD4 percentages for a set of young children with HIV who were measured several times over a period of two years. The dataset also includes the ages of the children at each measurement.

```{r,echo=FALSE}
# Read in the data from an excel-format ".csv" file
hiv.data.raw <- fread ("http://www.stat.columbia.edu/~gelman/arm/examples/cd4/allvar.csv")

invisible(hiv.data.raw[,ok := !is.na(CD4PCT) ])

hiv.data<-hiv.data.raw[ok==TRUE]
invisible(hiv.data[,y :=sqrt (CD4PCT)])
 # kid's age (yrs) at the beginning of the study
invisible(hiv.data[,age.baseline := baseage ]  ) 
# kids age (yrs) at the time of measurement
invisible(hiv.data[,age.measurement := visage ] ) 
invisible(hiv.data[,time := visage - baseage ] )
setnames(hiv.data,"treatmnt","treatment") 
hiv.data<-hiv.data[complete.cases(hiv.data[,list(y,time,age.baseline,treatment)])]
```

1. Graph the outcome (the CD4 percentage, on the square root scale) for each child as a function of time.
```{r}
ggplot(data = hiv.data, aes(x=time,y=y))+geom_point()+geom_smooth()
```

2. Each child's data has a time course that can be summarized by a linear fit. Estimate these lines and plot them for all the children.

```{r}
# Build linear regression model - complete pooling
hiv_reg_np <- lm(y~time+factor(newpid)-1, data=hiv.data)
summary(hiv_reg_np)

# Plot each child
ggplot(hiv.data, aes(x=time,y=y,group=newpid))+geom_line()
```


3. Set up a model for the children's slopes and intercepts as a function of the treatment and age at baseline. Estimate this model using the two-step procedure first estimate the intercept and slope separately for each child, then fit the between-child models using the point estimates from the first step.
```{r}
# Create matrix to store coefficients
np_hiv_coef <- matrix(NA, nrow = 254, ncol = 3)
colnames(np_hiv_coef) <- c("newpid","intercept","slope")
# Insert value into the matrix
for (i in unique(hiv.data$newpid)) {
  cp <- lm(y~time, data = hiv.data[newpid==i,])
  np_hiv_coef[i,1] <- i
  np_hiv_coef[i,2] <- coef(cp)[1]
  np_hiv_coef[i,3] <- coef(cp)[2]
}
# Merge two matrix 
treat_age <- hiv.data[,list(age.baseline=unique(age.baseline),treatment=unique(treatment)), by=newpid]
mergetwo <- merge(np_hiv_coef,treat_age,by="newpid")
# Regress intercept and slope
lm(intercept~ age.baseline+factor(treatment),data = mergetwo)
lm(slope~ age.baseline+factor(treatment),data=mergetwo)
```


4. Write a model predicting CD4 percentage as a function of time with varying intercepts across children. Fit using `lmer()` and interpret the coefficient for time.
```{r}
hiv_reg_vi <- lmer(y~time+(1|newpid), data = hiv.data)
summary(hiv_reg_vi)
head(ranef(hiv_reg_vi)$newpid)
```
\color{blue}Based on the result table, we have regression model: $y=4.76-0.37time$

As time goes on, the CD4 percentage will be decrease. Meanwhile, different child will have different CD4 percentage at each time period, since there are random effects among children.

When calculating CD4 for each child, we need to add the random effects at the end of the model, for example, the model for the first child will be The first child: $y=4.76-0.37time-0.2$, where -0.2 is the random effect.\color{black}

5. Extend the model in (4) to include child-level predictors (that is, group-level predictors) for treatment and age at baseline. Fit using `lmer()` and interpret the coefficients on time, treatment, and age at baseline.

```{r}
hiv_reg_vis <- lmer(y~time+factor(treatment)+age.baseline+(1|newpid), data = hiv.data)
summary(hiv_reg_vis)
head(ranef(hiv_reg_vis)$newpid)
```
\color{blue}Based on the result table, we have the regression model: $y=4.91-0.36time+0.18treatment-0.12age.baseline$

Time and age have negative effects on CD4 while treatment has positive effetcs.

When calculating CD4 for each child, we need to add the random effects at the end of the model, for example, the model for the first child will be The first child: $y=4.91-0.36time+0.18treatment-0.12age.baseline-0.07$, where -0.07 is the random effect.\color{black}

6. Investigate the change in partial pooling from (4) to (5) both graphically and numerically.

```{r}
anova(hiv_reg_vi,hiv_reg_vis)
par(mfrow=c(1,2))
plot(fitted(hiv_reg_vi),resid(hiv_reg_vi,type="pearson"),col="blue")
plot(fitted(hiv_reg_vis),resid(hiv_reg_vis,type="pearson"),col="red")
```
\color{blue} The model in (5) has a slightly better AIC and edviance.\color{black}

7. Use the model fit from (5) to generate simulation of predicted CD4 percentages for each child in the dataset at a hypothetical next time point.

```{r}
library(dplyr)
predict_data <- subset(hiv.data, !is.na(hiv.data$treatment) & !is.na(age.baseline))
predict_new <- predict(hiv_reg_vis,newdata=predict_data)
predict_cmb <- cbind(predict_new,predict_data)
colnames(predict_cmb)[1] <- c("prediction")
ggplot(predict_cmb,aes(x=prediction))+geom_histogram()
```

8. Use the same model fit to generate simulations of CD4 percentages at each of the time periods for a new child who was 4 years old at baseline.

```{r}
pred_data_2 <- subset(hiv.data, !is.na(hiv.data$treatment) & !is.na(age.baseline))
pred_data_2 <- pred_data_2[, -c(1, 4, 5, 6, 8)]
pred_data_2 <- pred_data_2[which(round(pred_data_2$age.baseline) == 4 ),]
pred_new_8 <- predict(hiv_reg_vis, newdata=pred_data_2)
hist(pred_new_8)
```


9. Posterior predictive checking: continuing the previous exercise, use the fitted model from (5) to simulate a new dataset of CD4 percentages (with the same sample size and ages of the original dataset) for the final time point of the study, and record the average CD4 percentage in this sample. Repeat this process 1000 times and compare the simulated distribution to the observed CD4 percentage at the final time point for the actual data.
```{r}
# Using model - hiv_reg_vis from (5)
pred_new_9 <- hiv.data[,list(time=max(time),age.baseline=unique(age.baseline),
                       treatment=unique(treatment)),by =newpid]
cm3<-coef(hiv_reg_vis)$newpid
sigy<-sigma.hat(hiv_reg_vis)$sigma$data
predy<-cm3[,1]+cm3[,2]*pred_new_9$time+cm3[,3]*pred_new_9$age.baseline+cm3[,4]*(pred_new_9$treatment-1)
avg.pred.CD4PCT<-NULL
simupred<-matrix(NA,nrow(pred_new_9),1000)
for (i in 1:1000){
  ytilde<-rnorm(predy,sigy)
  simupred[,1]<-ytilde
}
hist(simupred)
```

10. Extend the model to allow for varying slopes for the time predictor.
```{r}
# Assume random slope and intercept are correlated
hiv_reg_vslope <- lmer(y~time+factor(treatment)+age.baseline+(1+time|newpid), data = hiv.data)
summary(hiv_reg_vslope)
```


11. Next fit a model that does not allow for varying slopes but does allow for different coefficients for each time point (rather than fitting the linear trend).
```{r}
hiv_reg_11 <- lmer(y~factor(time)+(1|newpid), data = hiv.data)
```
\color{blue} Since I factorized the time, there are lots of levels of time in the outcome table. \color{black}

12. Compare the results of these models both numerically and graphically.
```{r}
anova(hiv_reg_11,hiv_reg_vslope,hiv_reg_vis,hiv_reg_vi)
```
\color{blue} The AIC an deviance of each model are pretty close, however, the varying slope model has the best AIC and lowest deviance. \color{black}

## Figure skate in the 1932 Winter Olympics

The folder olympics has seven judges' ratings of seven figure skaters (on two criteria: "technical merit" and "artistic impression") from the 1932 Winter Olympics. Take a look at 
http://www.stat.columbia.edu/~gelman/arm/examples/olympics/olympics1932.txt
```{r,echo=FALSE}
filename<- "http://www.stat.columbia.edu/~gelman/arm/examples/olympics/olympics1932.txt"
olympics1932_na<-read.fwf(filename,widths=c(2,14,9,9,9,9,9,9,9),skip=21,header = FALSE)
colnames(olympics1932_na)<- c("pair", "criterion", "judge_1",  "judge_2",  "judge_3",
                              "judge_4",  "judge_5" , "judge_6",  "judge_7")

olympics1932<-na.locf(olympics1932_na)
olympics1932$criterion<-str_trim(olympics1932_na$criterion)
```

1. Construct a $7\times 7 \times 2$ array of the data (ordered by skater, judge, and judging criterion).

```{r}
performance <- olympics1932 %>% filter(criterion=="Performance")
program <- olympics1932 %>% filter(criterion=="Program")
```

2. Reformulate the data as a $49\times 4$ array (similar to the top table in Figure 11.7), where the first two columns are the technical merit and artistic impression scores, the third column is a skater ID, and the fourth column is a judge ID.

```{r}
new_olympics <- matrix(NA, nrow = 49, ncol = 4)
colnames(new_olympics) <- c("pair","judge","performance","program")
new_olympics[,1] <- c(rep(1,7),rep(2,7),rep(3,7),rep(4,7),rep(5,7),rep(6,7),rep(7,7))
new_olympics[,2] <- rep(c("judge_1","judge_2","judge_3","judge_4","judge_5","judge_6","judge_7"),7)
p_score <- as.vector(t(performance[,3:9]))
pro_score <- as.vector(t(program[,3:9]))
new_olympics[,3] <- p_score
new_olympics[,4] <- pro_score
new_olympics <- data.frame(new_olympics)
```

3. Add another column to this matrix representing an indicator variable that equals 1 if the skater and judge are from the same country, or 0 otherwise.

```{r}
new_olympics2 <- new_olympics %>% mutate(samecountry=rep(0,49))
new_olympics2[5,5] <- 1
new_olympics2[14,5] <- 1
new_olympics2[15,5] <- 1
new_olympics2[22,5] <- 1
new_olympics2[49,5] <- 1
```

4. Write the notation for a non-nested multilevel model (varying across skaters and judges) for the technical merit ratings and fit using lmer().
```{r}
techmer <- lmer(as.numeric(program)~1+(1|pair)+(1|judge), data = new_olympics2)
summary(techmer)
```

5. Fit the model in (4) using the artistic impression ratings.
```{r}
artimp <- lmer(as.numeric(performance)~1+(1|pair)+(1|judge), data = new_olympics2)
summary(artimp)
```

6. Display your results for both outcomes graphically.

```{r}
# Plot on raw data
ggplot(new_olympics2,aes(x=pair,y=as.numeric(program),group=judge,color=judge))+
  geom_point()+geom_smooth(method = "lm", se= FALSE)+ggtitle("Technical scores")
ggplot(new_olympics2,aes(x=pair,y=as.numeric(performance),group=judge,color=judge))+
  geom_point()+geom_smooth(method = "lm", se= FALSE)+ggtitle("Artristic scores")
# Plot random effects among skaters
re_skater <- as.data.frame(cbind(unlist(ranef(techmer))[1:7],unlist(ranef(artimp))[1:7]))
re_skater$pair <-c(1:7) 
ggplot(data=re_skater)+
  geom_point(col="red",aes(x=pair,y=V1))+geom_smooth(method="loess",col="red",aes(x=pair,y=V1),se=FALSE)+
  geom_point(col="black",aes(x=pair,y=V2))+geom_smooth(method="loess",col="black",aes(x=pair,y=V2),se=FALSE)+
  ggtitle("Random effects for two models for each skater")+
  ylab("Random effects")
# Plot random effects among judges
re_judge <- as.data.frame(cbind(unlist(ranef(techmer))[1:7],unlist(ranef(artimp))[1:7]))
re_judge$judge <-c(1:7) 
ggplot(data=re_judge)+
  geom_point(col="red",aes(x=judge,y=V1))+geom_smooth(method="loess",col="red",aes(x=judge,y=V1),se=FALSE)+
  geom_point(col="black",aes(x=judge,y=V2))+geom_smooth(method="loess",col="black",aes(x=judge,y=V2),se=FALSE)+
  ggtitle("Random effects for two models for each judge")+
  ylab("Random effects")
```


## Different ways to write the model:

Using any data that are appropriate for a multilevel model, write the model in the five ways discussed in Section 12.5 of Gelman and Hill.
```{r }
# Using the HIV dataset and model from the first problem
hiv_reg_vis <- lmer(y~time+factor(treatment)+age.baseline+(1|newpid), data = hiv.data)
summary(hiv_reg_vis)
```
The fixed effects part of the model:
$y=\alpha_{j[i]}+\beta_{time}X_{itime}+\beta_{treatment}X_{itreatment}+\beta_{age.base}X_{iage.base}+\epsilon_i$

#1st method: Allowing regression coefficeints to vary accross groups
$y=4.91+X_{itime}*(-0.36)+X_{itreatment}*(-0.12)+X_{iage.base}*0.18+0.77$

$\alpha_j\sim\ \mathrm{N}(0,1.37^2)$

#2nd method: Combining separate local regressions
$y\sim\ N(4.91+X_{itime}*(-0.36)+X_{itreatment}*(-0.12)+X_{iage.base}*(0.18), 0.77^2)$

$\alpha_j\sim\ \mathrm{N}(Random Intercept,1.37^2)$

#3rd method: Modeling the coefficients of a large regression model
$y_i \sim\ N(4.91+X_{itime}*(-0.36)+X_{itreatment}*(-0.12)+X_{iage.base}*(0.18), 0.77^2)$

$\beta_j\sim\ N(0,1.37^2)$

#4th method: Regression with multiple error terms
$y_i \sim\ N(4.91+X_{itime}*(-0.36)+X_{itreatment}*(-0.12)+X_{iage.base}*(0.18)+1.37^2, 0.77^2)$

#5th method: Large regression with correlated errors
$y_i \sim\ N(4.91+X_{itime}*(-0.36)+X_{itreatment}*(-0.12)+X_{iage.base}*(0.18),1.37^2+0.77^2)$


## Models for adjusting individual ratings: 

A committee of 10 persons is evaluating 100 job applications. Each person on the committee reads 30 applications (structured so that each application is read by three people) and gives each a numerical rating between 1 and 10.


1. It would be natural to rate the applications based on their combined scores; however, there is a worry that different raters use different standards, and we would like to correct for this. Set up a model for the ratings (with parameters for the applicants and the raters).
$y_{score}=\alpha_{j[i]} + \beta_{cadidate}X_{iCadidate}+\beta_{rater}X_{iRater}+U_{RandomEffect-Rater}$

2. It is possible that some persons on the committee show more variation than others in their ratings. Expand your model to allow for this.

lmer(rating~applicants+raters+(1+raters|raters))

